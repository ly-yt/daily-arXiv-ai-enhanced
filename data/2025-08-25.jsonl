{"id": "2508.15858", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15858", "abs": "https://arxiv.org/abs/2508.15858", "authors": ["Maarten Buyl", "Yousra Fettach", "Guillaume Bied", "Tijl De Bie"], "title": "Building and Measuring Trust between Large Language Models", "comment": null, "summary": "As large language models (LLMs) increasingly interact with each other, most\nnotably in multi-agent setups, we may expect (and hope) that `trust'\nrelationships develop between them, mirroring trust relationships between human\ncolleagues, friends, or partners. Yet, though prior work has shown LLMs to be\ncapable of identifying emotional connections and recognizing reciprocity in\ntrust games, little remains known about (i) how different strategies to build\ntrust compare, (ii) how such trust can be measured implicitly, and (iii) how\nthis relates to explicit measures of trust.\n  We study these questions by relating implicit measures of trust, i.e.\nsusceptibility to persuasion and propensity to collaborate financially, with\nexplicit measures of trust, i.e. a dyadic trust questionnaire well-established\nin psychology. We build trust in three ways: by building rapport dynamically,\nby starting from a prewritten script that evidences trust, and by adapting the\nLLMs' system prompt. Surprisingly, we find that the measures of explicit trust\nare either little or highly negatively correlated with implicit trust measures.\nThese findings suggest that measuring trust between LLMs by asking their\nopinion may be deceiving. Instead, context-specific and implicit measures may\nbe more informative in understanding how LLMs trust each other."}
{"id": "2508.16410", "categories": ["cs.MA", "cs.DM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.16410", "abs": "https://arxiv.org/abs/2508.16410", "authors": ["Alvin Combrink", "Sabino Francesco Roselli", "Martin Fabian"], "title": "Sound and Solution-Complete CCBS", "comment": "15 pages", "summary": "Continuous-time Conflict Based-Search (CCBS) has long been viewed as the\nde-facto optimal solver for multi-agent path finding in continuous time\n(MAPFR). Recent findings, however, show that the original theoretical variant\nof CCBS can suffer from non-termination, while the widely used implementation\ncan return sub-optimal solutions. We introduce an analytical framework that\nyields simple and sufficient conditions under which any CCBS-style algorithm is\nboth sound, i.e., returns only optimal solutions, and solution complete, i.e.,\nterminates on every solvable MAPFR instance. Investigating the publicly\navailable implementation of CCBS reveals that it violates these conditions.\nThough this merely indicates that CCBS might be unsound, this indication is\nsupported by counter-examples.\n  Leveraging the analytical framework, we propose a novel branching rule and\nprove that it satisfies the sufficient conditions, thereby restoring soundness\nand termination guarantees. Consequently, the resulting CCBS variant is both\nsound and solution complete, matching the guarantees of the discrete-time CBS\nfor the first time in the continuous domain. We experimentally apply standard\nCCBS and CCBS under our branching rule to an example problem, with our\nbranching rule returning a solution with lower sum-of-costs than standard CCBS.\nBecause the branching rule largely only affects the branching step, it can be\nadopted as a drop-in replacement in existing code-bases, as we show in our\nprovided implementation. Beyond CCBS, the analytical framework and termination\ncriterion provide a systematic way to evaluate other CCBS-like MAPFR solvers\nand future extensions."}
{"id": "2508.16440", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.16440", "abs": "https://arxiv.org/abs/2508.16440", "authors": ["Surya Murthy", "Zhenyu Gao", "John-Paul Clarke", "Ufuk Topcu"], "title": "Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework", "comment": null, "summary": "Urban Air Mobility (UAM) envisions the widespread use of small aerial\nvehicles to transform transportation in dense urban environments. However, UAM\nfaces critical operational challenges, particularly the balance between\nminimizing noise exposure and maintaining safe separation in low-altitude urban\nairspace, two objectives that are often addressed separately. We propose a\nreinforcement learning (RL)-based air traffic management system that integrates\nboth noise and safety considerations within a unified, decentralized framework.\nUnder this scalable air traffic coordination solution, agents operate in a\nstructured, multi-layered airspace and learn altitude adjustment policies to\njointly manage noise impact and separation constraints. The system demonstrates\nstrong performance across both objectives and reveals tradeoffs among\nseparation, noise exposure, and energy efficiency under high traffic density.\nThe findings highlight the potential of RL and multi-objective coordination\nstrategies in enhancing the safety, quietness, and efficiency of UAM\noperations."}
{"id": "2508.16508", "categories": ["cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.16508", "abs": "https://arxiv.org/abs/2508.16508", "authors": ["Siddharth Chaturvedi", "Ahmed El-Gazzar", "Marcel van Gerven"], "title": "Abmax: A JAX-based Agent-based Modeling Framework", "comment": "12 pages, 7 figures, 4 tables, 2 algorithms", "summary": "Agent-based modeling (ABM) is a principal approach for studying complex\nsystems. By decomposing a system into simpler, interacting agents, agent-based\nmodeling (ABM) allows researchers to observe the emergence of complex\nphenomena. High-performance array computing libraries like JAX can help scale\nsuch computational models to a large number of agents by using automatic\nvectorization and just-in-time (JIT) compilation. One of the caveats of using\nJAX to achieve such scaling is that the shapes of arrays used in the\ncomputational model should remain immutable throughout the simulation. In the\ncontext of agent-based modeling (ABM), this can pose constraints on certain\nagent manipulation operations that require flexible data structures. A subset\nof which is represented by the ability to update a dynamically selected number\nof agents by applying distinct changes to them during a simulation. To this\neffect, we introduce Abmax, an ABM framework based on JAX that implements\nmultiple just-in-time (JIT) compilable algorithms to provide this\nfunctionality. On the canonical predation model benchmark, Abmax achieves\nruntime performance comparable to state-of-the-art implementations. Further, we\nshow that this functionality can also be vectorized, making it possible to run\nmany similar agent-based models in parallel. We also present two examples in\nthe form of a traffic-flow model and a financial market model to show the use\ncase of Abmax."}
{"id": "2508.15943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15943", "abs": "https://arxiv.org/abs/2508.15943", "authors": ["Riccardo Andreoni", "Andrei Buliga", "Alessandro Daniele", "Chiara Ghidini", "Marco Montali", "Massimiliano Ronzani"], "title": "T-ILR: a Neurosymbolic Integration for LTLf", "comment": "Accepted for presentation at NeSy 2025. 10 pages", "summary": "State-of-the-art approaches for integrating symbolic knowledge with deep\nlearning architectures have demonstrated promising results in static domains.\nHowever, methods to handle temporal logic specifications remain underexplored.\nThe only existing approach relies on an explicit representation of a\nfinite-state automaton corresponding to the temporal specification. Instead, we\naim at proposing a neurosymbolic framework designed to incorporate temporal\nlogic specifications, expressed in Linear Temporal Logic over finite traces\n(LTLf), directly into deep learning architectures for sequence-based tasks. We\nextend the Iterative Local Refinement (ILR) neurosymbolic algorithm, leveraging\nthe recent introduction of fuzzy LTLf interpretations. We name this proposed\nmethod Temporal Iterative Local Refinement (T-ILR). We assess T-ILR on an\nexisting benchmark for temporal neurosymbolic architectures, consisting of the\nclassification of image sequences in the presence of temporal knowledge. The\nresults demonstrate improved accuracy and computational efficiency compared to\nthe state-of-the-art method."}
{"id": "2508.16571", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.16571", "abs": "https://arxiv.org/abs/2508.16571", "authors": ["Alisa Vinogradova", "Vlad Vinogradov", "Dmitrii Radkevich", "Ilya Yasny", "Dmitry Kobyzev", "Ivan Izmailov", "Katsiaryna Yanchanka", "Andrey Doronichev"], "title": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence", "comment": null, "summary": "In this paper, we describe and benchmark a competitor-discovery component\nused within an agentic AI system for fast drug asset due diligence. A\ncompetitor-discovery AI agent, given an indication, retrieves all drugs\ncomprising the competitive landscape of that indication and extracts canonical\nattributes for these drugs. The competitor definition is investor-specific, and\ndata is paywalled/licensed, fragmented across registries, ontology-mismatched\nby indication, alias-heavy for drug names, multimodal, and rapidly changing.\nAlthough considered the best tool for this problem, the current LLM-based AI\nsystems aren't capable of reliably retrieving all competing drug names, and\nthere is no accepted public benchmark for this task. To address the lack of\nevaluation, we use LLM-based agents to transform five years of multi-modal,\nunstructured diligence memos from a private biotech VC fund into a structured\nevaluation corpus mapping indications to competitor drugs with normalized\nattributes. We also introduce a competitor validating LLM-as-a-judge agent that\nfilters out false positives from the list of predicted competitors to maximize\nprecision and suppress hallucinations. On this benchmark, our\ncompetitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research\n(65%) and Perplexity Labs (60%). The system is deployed in production with\nenterprise users; in a case study with a biotech VC investment fund, analyst\nturnaround time dropped from 2.5 days to $\\sim$3 hours ($\\sim$20x) for the\ncompetitive analysis."}
{"id": "2508.16033", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16033", "abs": "https://arxiv.org/abs/2508.16033", "authors": ["Jong-Hwan Jang", "Junho Song", "Yong-Yeon Jo"], "title": "CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics", "comment": "Demo paper, 5 pages", "summary": "Recognizing the need for explainable AI (XAI) approaches to enable the\nsuccessful integration of AI-based ECG prediction models (AI-ECG) into clinical\npractice, we introduce a framework generating \\textbf{Co}unter\\textbf{F}actual\n\\textbf{E}CGs (i,e., named CoFE) to illustrate how specific features, such as\namplitudes and intervals, influence the model's predictive decisions. To\ndemonstrate the applicability of the CoFE, we present two case studies: atrial\nfibrillation classification and potassium level regression models. The CoFE\nreveals feature changes in ECG signals that align with the established clinical\nknowledge. By clarifying both \\textbf{where valid features appear} in the ECG\nand \\textbf{how they influence the model's predictions}, we anticipate that our\nframework will enhance the interpretability of AI-ECG models and support more\neffective clinical decision-making. Our demonstration video is available at:\nhttps://www.youtube.com/watch?v=YoW0bNBPglQ."}
{"id": "2508.16051", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16051", "abs": "https://arxiv.org/abs/2508.16051", "authors": ["Yiheng Hu", "Xiaoyang Wang", "Qing Liu", "Xiwei Xu", "Qian Fu", "Wenjie Zhang", "Liming Zhu"], "title": "MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs", "comment": null, "summary": "Multimodal Multi-hop question answering requires integrating information from\ndiverse sources, such as images and texts, to derive answers. Existing methods\ntypically rely on sequential retrieval and reasoning, where each step builds on\nthe previous output. However, this single-path paradigm makes them vulnerable\nto errors due to misleading intermediate steps. Moreover, developing multimodal\nmodels can be computationally expensive, often requiring extensive training. To\naddress these limitations, we propose a training-free framework guided by an\nAdaptive Planning Graph, which consists of planning, retrieval and reasoning\nmodules. The planning module analyzes the current state of the Adaptive\nPlanning Graph, determines the next action and where to expand the graph, which\nenables dynamic and flexible exploration of reasoning paths. To handle\nretrieval of text to unspecified target modalities, we devise modality-specific\nstrategies that dynamically adapt to distinct data types. Our approach\npreserves the characteristics of multimodal information without costly\ntask-specific training, enabling seamless integration with up-to-date models.\nFinally, the experiments on MultimodalQA and WebQA show that our approach\nmatches or outperforms existing models that rely on training."}
{"id": "2508.16054", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.16054", "abs": "https://arxiv.org/abs/2508.16054", "authors": ["Sonish Sivarajkumar", "Hang Zhang", "Yuelyu Ji", "Maneesh Bilalpur", "Xizhi Wu", "Chenyu Li", "Min Gu Kwak", "Shyam Visweswaran", "Yanshan Wang"], "title": "Generative Foundation Model for Structured and Unstructured Electronic Health Records", "comment": null, "summary": "Electronic health records (EHRs) are rich clinical data sources but complex\nrepositories of patient data, spanning structured elements (demographics,\nvitals, lab results, codes), unstructured clinical notes and other modalities\nof data. Harnessing this heterogeneity is critical for improving patient\noutcomes. Recent advances in large language models (LLMs) have enabled\nfoundation models that can learn from multiple data modalities and support\nclinical tasks. However, most current approaches simply serialize numeric EHR\ndata into text, which risks losing temporal and quantitative detail. We\nintroduce Generative Deep Patient (GDP), a multimodal foundation model that\nnatively encodes structured EHR time-series via a CNN-Transformer encoder and\nfuses it with unstructured EHRs through cross-modal attention into a\nLLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,\nwhere it learns to produce clinical narratives from raw patient timelines while\nalso performing masked feature prediction (MFP) and next time-step prediction\n(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for\nclinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day\nreadmission). In clinical prediction, GDP demonstrated superior performance on\nMIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and\n30-day readmission AUROC = 0.627. For narrative generation, GDP achieved\nROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,\nGDP-Instruct scored highest on faithfulness, fluency, and overall clinical\nutility, suggesting reduced hospital documentation workload without sacrificing\naccuracy. Our results demonstrate that a single multimodal foundation model can\nboth predict clinically actionable events and generate high-quality clinical\nnarratives. Furthermore, GDP's flexible architecture can be extended to\nadditional modalities."}
{"id": "2508.16057", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.16057", "abs": "https://arxiv.org/abs/2508.16057", "authors": ["Sijie Yang", "Binyu Lei", "Filip Biljecki"], "title": "Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework", "comment": "Presented at 19th International Conference on Computational Urban\n  Planning and Urban Management (CUPUM 2025)", "summary": "Ensuring liveability and comfort is one of the fundamental objectives of\nurban planning. Numerous studies have employed computational methods to assess\nand quantify factors related to urban comfort such as greenery coverage,\nthermal comfort, and walkability. However, a clear definition of urban comfort\nand its comprehensive evaluation framework remain elusive. Our research\nexplores the theoretical interpretations and methodologies for assessing urban\ncomfort within digital planning, emphasising three key dimensions:\nmultidimensional analysis, data support, and AI assistance."}
{"id": "2508.16059", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.16059", "abs": "https://arxiv.org/abs/2508.16059", "authors": ["Zhuomin Chen", "Dan Li", "Jiahui Zhou", "Shunyu Wu", "Haozheng Ye", "Jian Lou", "See-Kiong Ng"], "title": "Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting", "comment": "To be published in CIKM 2025", "summary": "Time series (TS) data are ubiquitous across various application areas,\nrendering time series forecasting (TSF) a fundamental task. With the astounding\nadvances in large language models (LLMs), a variety of methods have been\ndeveloped to adapt LLMs for time series forecasting. Despite unlocking the\npotential of LLMs in comprehending TS data, existing methods are inherently\nconstrained by their shallow integration of TS information, wherein LLMs\ntypically access TS representations at shallow layers, primarily at the input\nlayer. This causes the influence of TS representations to progressively fade in\ndeeper layers and eventually leads to ineffective adaptation between textual\nembeddings and TS representations. In this paper, we propose the Multi-layer\nSteerable Embedding Fusion (MSEF), a novel framework that enables LLMs to\ndirectly access time series patterns at all depths, thereby mitigating the\nprogressive loss of TS information in deeper layers. Specifically, MSEF\nleverages off-the-shelf time series foundation models to extract semantically\nrich embeddings, which are fused with intermediate text representations across\nLLM layers via layer-specific steering vectors. These steering vectors are\ndesigned to continuously optimize the alignment between time series and textual\nmodalities and facilitate a layer-specific adaptation mechanism that ensures\nefficient few-shot learning capabilities. Experimental results on seven\nbenchmarks demonstrate significant performance improvements by MSEF compared\nwith baselines, with an average reduction of 31.8% in terms of MSE. The code is\navailable at https://github.com/One1sAll/MSEF."}
{"id": "2508.16072", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.16072", "abs": "https://arxiv.org/abs/2508.16072", "authors": ["Zizhen Li", "Chuanhao Li", "Yibin Wang", "Qi Chen", "Diping Song", "Yukang Feng", "Jianwen Sun", "Jiaxin Ai", "Fanrui Zhang", "Mingzhu Sun", "Kaipeng Zhang"], "title": "InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles", "comment": "EMNLP 2025 MainConference", "summary": "LLMs have shown strong performance on human-centric reasoning tasks. While\nprevious evaluations have explored whether LLMs can infer intentions or detect\ndeception, they often overlook the individualized reasoning styles that\ninfluence how people interpret and act in social contexts. Social deduction\ngames (SDGs) provide a natural testbed for evaluating individualized reasoning\nstyles, where different players may adopt diverse but contextually valid\nreasoning strategies under identical conditions. To address this, we introduce\nInMind, a cognitively grounded evaluation framework designed to assess whether\nLLMs can capture and apply personalized reasoning styles in SDGs. InMind\nenhances structured gameplay data with round-level strategy traces and\npost-game reflections, collected under both Observer and Participant modes. It\nsupports four cognitively motivated tasks that jointly evaluate both static\nalignment and dynamic adaptation. As a case study, we apply InMind to the game\nAvalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o\nfrequently rely on lexical cues, struggling to anchor reflections in temporal\ngameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs\nlike DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These\nfindings reveal key limitations in current LLMs' capacity for individualized,\nadaptive reasoning, and position InMind as a step toward cognitively aligned\nhuman-AI interaction."}
{"id": "2508.16112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16112", "abs": "https://arxiv.org/abs/2508.16112", "authors": ["Heewoong Noh", "Namkyeong Lee", "Gyoung S. Na", "Kibum Kim", "Chanyoung Park"], "title": "IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra", "comment": null, "summary": "Spectral analysis provides crucial clues for the elucidation of unknown\nmaterials. Among various techniques, infrared spectroscopy (IR) plays an\nimportant role in laboratory settings due to its high accessibility and low\ncost. However, existing approaches often fail to reflect expert analytical\nprocesses and lack flexibility in incorporating diverse types of chemical\nknowledge, which is essential in real-world analytical scenarios. In this\npaper, we propose IR-Agent, a novel multi-agent framework for molecular\nstructure elucidation from IR spectra. The framework is designed to emulate\nexpert-driven IR analysis procedures and is inherently extensible. Each agent\nspecializes in a specific aspect of IR interpretation, and their complementary\nroles enable integrated reasoning, thereby improving the overall accuracy of\nstructure elucidation. Through extensive experiments, we demonstrate that\nIR-Agent not only improves baseline performance on experimental IR spectra but\nalso shows strong adaptability to various forms of chemical information."}
{"id": "2508.16117", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.16117", "abs": "https://arxiv.org/abs/2508.16117", "authors": ["Saransh Kumar Gupta", "Rizwan Gulzar Mir", "Lipika Dey", "Partha Pratim Das", "Anirban Sen", "Ramesh Jain"], "title": "Extending FKG.in: Towards a Food Claim Traceability Network", "comment": "10 pages, 3 figures, 1 table, 45 references, ACM International\n  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop", "summary": "The global food landscape is rife with scientific, cultural, and commercial\nclaims about what foods are, what they do, what they should not do, or should\nnot do. These range from rigorously studied health benefits (probiotics improve\ngut health) and misrepresentations (soaked almonds make one smarter) to vague\npromises (superfoods boost immunity) and culturally rooted beliefs (cold foods\ncause coughs). Despite their widespread influence, the infrastructure for\ntracing, verifying, and contextualizing these claims remains fragmented and\nunderdeveloped. In this paper, we propose a Food Claim-Traceability Network\n(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have\nbeen incrementally building. We also present the ontology design and the\nsemi-automated knowledge curation workflow that we used to develop a proof of\nconcept of FKG.in-FCN using Reddit data and Large Language Models. FCN\nintegrates curated data inputs, structured schemas, and provenance-aware\npipelines for food-related claim extraction and validation. While directly\nlinked to the Indian food knowledge graph as an application, our methodology\nremains application-agnostic and adaptable to other geographic, culinary, or\nregulatory settings. By modeling food claims and their traceability in a\nstructured, verifiable, and explainable way, we aim to contribute to more\ntransparent and accountable food knowledge ecosystems, supporting researchers,\npolicymakers, and most importantly, everyday consumers in navigating a world\nsaturated with dietary assertions."}
{"id": "2508.16129", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16129", "abs": "https://arxiv.org/abs/2508.16129", "authors": ["Ruiqi Wu", "Yuang Yao", "Tengfei Ma", "Chenran Zhang", "Na Su", "Tao Zhou", "Geng Chen", "Wen Fan", "Yi Zhou"], "title": "Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning", "comment": null, "summary": "Multimodal large language models (MLLMs) have recently demonstrated\nremarkable reasoning abilities with reinforcement learning paradigm. Although\nseveral multimodal reasoning models have been explored in the medical domain,\nmost of them focus exclusively on basic reasoning, which refers to shallow\ninference based on visual feature matching. However, real-world clinical\ndiagnosis extends beyond basic reasoning, demanding reasoning processes that\nintegrate heterogeneous clinical information (such as chief complaints and\nmedical history) with multimodal medical imaging data. To bridge this gap, we\nintroduce MM-Retinal-Reason, the first ophthalmic multimodal dataset with the\nfull spectrum of perception and reasoning. It encompasses both basic reasoning\ntasks and complex reasoning tasks, aiming to enhance visual-centric fundamental\nreasoning capabilities and emulate realistic clinical thinking patterns.\nBuilding upon MM-Retinal-Reason, we propose OphthaReason, the first\nophthalmology-specific multimodal reasoning model with step-by-step reasoning\ntraces. To enable flexible adaptation to both basic and complex reasoning\ntasks, we specifically design a novel method called Uncertainty-Aware Dynamic\nThinking (UADT), which estimates sample-level uncertainty via entropy and\ndynamically modulates the model's exploration depth using a shaped advantage\nmechanism. Comprehensive experiments demonstrate that our model achieves\nstate-of-the-art performance on both basic and complex reasoning tasks,\noutperforming general-purpose MLLMs, medical MLLMs, RL-based medical MLLMs, and\nophthalmic MLLMs by at least 24.92\\%, 15.00\\%, 21.20\\%, and 17.66\\%. Project\nPage: \\href{https://github.com/lxirich/OphthaReason}{link}."}
{"id": "2508.16172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16172", "abs": "https://arxiv.org/abs/2508.16172", "authors": ["Kai Hu", "Parfait Atchade-Adelomou", "Carlo Adornetto", "Adrian Mora-Carrero", "Luis Alonso-Pastor", "Ariel Noyman", "Yubo Liu", "Kent Larson"], "title": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain", "comment": null, "summary": "Understanding human behavior in urban environments is a crucial field within\ncity sciences. However, collecting accurate behavioral data, particularly in\nnewly developed areas, poses significant challenges. Recent advances in\ngenerative agents, powered by Large Language Models (LLMs), have shown promise\nin simulating human behaviors without relying on extensive datasets.\nNevertheless, these methods often struggle with generating consistent,\ncontext-sensitive, and realistic behavioral outputs. To address these\nlimitations, this paper introduces the Preference Chain, a novel method that\nintegrates Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance\ncontext-aware simulation of human behavior in transportation systems.\nExperiments conducted on the Replica dataset demonstrate that the Preference\nChain outperforms standard LLM in aligning with real-world transportation mode\nchoices. The development of the Mobility Agent highlights potential\napplications of proposed method in urban mobility modeling for emerging cities,\npersonalized travel behavior analysis, and dynamic traffic forecasting. Despite\nlimitations such as slow inference and the risk of hallucination, the method\noffers a promising framework for simulating complex human behavior in\ndata-scarce environments, where traditional data-driven models struggle due to\nlimited data availability."}
{"id": "2508.16204", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2508.16204", "abs": "https://arxiv.org/abs/2508.16204", "authors": ["Jo√£o Abrantes", "Robert Tjarko Lange", "Yujin Tang"], "title": "Competition and Attraction Improve Model Fusion", "comment": "Accepted at GECCO 2025 as a full paper", "summary": "Model merging is a powerful technique for integrating the specialized\nknowledge of multiple machine learning models into a single model. However,\nexisting methods require manually partitioning model parameters into fixed\ngroups for merging, which restricts the exploration of potential combinations\nand limits performance. To overcome these limitations, we propose Model Merging\nof Natural Niches (M2N2), an evolutionary algorithm with three key features:\n(1) dynamic adjustment of merging boundaries to progressively explore a broader\nrange of parameter combinations; (2) a diversity preservation mechanism\ninspired by the competition for resources in nature, to maintain a population\nof diverse, high-performing models that are particularly well-suited for\nmerging; and (3) a heuristicbased attraction metric to identify the most\npromising pairs of models for fusion. Our experimental results demonstrate, for\nthe first time, that model merging can be used to evolve models entirely from\nscratch. Specifically, we apply M2N2 to evolve MNIST classifiers from scratch\nand achieve performance comparable to CMA-ES, while being computationally more\nefficient. Furthermore, M2N2 scales to merge specialized language and image\ngeneration models, achieving state-of-the-art performance. Notably, it\npreserves crucial model capabilities beyond those explicitly optimized by the\nfitness function, highlighting its robustness and versatility. Our code is\navailable at https://github.com/SakanaAI/natural_niches"}
{"id": "2508.16277", "categories": ["cs.AI", "cs.HC", "68T01, 68T05, 68T42, 91A80", "I.2; K.4"], "pdf": "https://arxiv.org/pdf/2508.16277", "abs": "https://arxiv.org/abs/2508.16277", "authors": ["Alexandru Tugui"], "title": "The next question after Turing's question: Introducing the Grow-AI test", "comment": "9th International Conference on Inventive Systems and Control ICISC\n  2025", "summary": "This study aims to extend the framework for assessing artificial\nintelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom),\ndesigned to answer the question \"Can machines grow up?\" -- a natural successor\nto the Turing Test. The methodology applied is based on a system of six primary\ncriteria (C1-C6), each assessed through a specific \"game\", divided into four\narenas that explore both the human dimension and its transposition into AI. All\ndecisions and actions of the entity are recorded in a standardized AI Journal,\nthe primary source for calculating composite scores. The assessment uses the\nprior expert method to establish initial weights, and the global score -- Grow\nUp Index -- is calculated as the arithmetic mean of the six scores, with\ninterpretation on maturity thresholds. The results show that the methodology\nallows for a coherent and comparable assessment of the level of \"growth\" of AI\nentities, regardless of their type (robots, software agents, LLMs). The\nmulti-game structure highlights strengths and vulnerable areas, and the use of\na unified journal guarantees traceability and replicability in the evaluation.\nThe originality of the work lies in the conceptual transposition of the process\nof \"growing\" from the human world to that of artificial intelligence, in an\nintegrated testing format that combines perspectives from psychology, robotics,\ncomputer science, and ethics. Through this approach, GROW-AI not only measures\nperformance but also captures the evolutionary path of an AI entity towards\nmaturity."}
{"id": "2508.16279", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16279", "abs": "https://arxiv.org/abs/2508.16279", "authors": ["Dawei Gao", "Zitao Li", "Yuexiang Xie", "Weirui Kuang", "Liuyi Yao", "Bingchen Qian", "Zhijian Ma", "Yue Cui", "Haohao Luo", "Shen Li", "Lu Yi", "Yi Yu", "Shiqi He", "Zhiling Luo", "Wenmeng Zhou", "Zhicheng Zhang", "Xuguang He", "Ziqian Chen", "Weikai Liao", "Farruh Isakulovich Kushnazarov", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications", "comment": null, "summary": "Driven by rapid advancements of Large Language Models (LLMs), agents are\nempowered to combine intrinsic knowledge with dynamic tool use, greatly\nenhancing their capacity to address real-world tasks. In line with such an\nevolution, AgentScope introduces major improvements in a new version (1.0),\ntowards comprehensively supporting flexible and efficient tool-based\nagent-environment interactions for building agentic applications. Specifically,\nwe abstract foundational components essential for agentic applications and\nprovide unified interfaces and extensible modules, enabling developers to\neasily leverage the latest progress, such as new models and MCPs. Furthermore,\nwe ground agent behaviors in the ReAct paradigm and offer advanced agent-level\ninfrastructure based on a systematic asynchronous design, which enriches both\nhuman-agent and agent-agent interaction patterns while improving execution\nefficiency. Building on this foundation, we integrate several built-in agents\ntailored to specific practical scenarios. AgentScope also includes robust\nengineering support for developer-friendly experiences. We provide a scalable\nevaluation module with a visual studio interface, making the development of\nlong-trajectory agentic applications more manageable and easier to trace. In\naddition, AgentScope offers a runtime sandbox to ensure safe agent execution\nand facilitates rapid deployment in production environments. With these\nenhancements, AgentScope provides a practical foundation for building scalable,\nadaptive, and effective agentic applications."}
{"id": "2508.16292", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.16292", "abs": "https://arxiv.org/abs/2508.16292", "authors": ["Wen-Han Hsieh", "Elvis Hsieh", "Dantong Niu", "Trevor Darrell", "Roei Herzig", "David M. Chan"], "title": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible", "comment": "9 pages, 2 figures, 1 table", "summary": "Recently, Vision-Language-Action (VLA) models have demonstrated strong\nperformance on a range of robotic tasks. These models rely on multimodal\ninputs, with language instructions playing a crucial role -- not only in\npredicting actions, but also in robustly interpreting user intent, even when\nthe requests are impossible to fulfill. In this work, we investigate how VLAs\ncan recognize, interpret, and respond to false-premise instructions: natural\nlanguage commands that reference objects or conditions absent from the\nenvironment. We propose Instruct-Verify-and-Act (IVA), a unified framework that\n(i) detects when an instruction cannot be executed due to a false premise, (ii)\nengages in language-based clarification or correction, and (iii) grounds\nplausible alternatives in perception and action. Towards this end, we construct\na large-scale instruction tuning setup with structured language prompts and\ntrain a VLA model capable of handling both accurate and erroneous requests. Our\napproach leverages a contextually augmented, semi-synthetic dataset containing\npaired positive and false-premise instructions, enabling robust detection and\nnatural language correction. Our experiments show that IVA improves false\npremise detection accuracy by 97.56% over baselines, while increasing\nsuccessful responses in false-premise scenarios by 50.78%."}
{"id": "2508.16352", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16352", "abs": "https://arxiv.org/abs/2508.16352", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management", "comment": null, "summary": "Efficient and reliable beam alignment is a critical requirement for mmWave\nmultiple-input multiple-output (MIMO) systems, especially in 6G and beyond,\nwhere communication must be fast, adaptive, and resilient to real-world\nuncertainties. Existing deep learning (DL)-based beam alignment methods often\nneglect the underlying causal relationships between inputs and outputs, leading\nto limited interpretability, poor generalization, and unnecessary beam sweeping\noverhead. In this work, we propose a causally-aware DL framework that\nintegrates causal discovery into beam management pipeline. Particularly, we\npropose a novel two-stage causal beam selection algorithm to identify a minimal\nset of relevant inputs for beam prediction. First, causal discovery learns a\nBayesian graph capturing dependencies between received power inputs and the\noptimal beam. Then, this graph guides causal feature selection for the DL-based\nclassifier. Simulation results reveal that the proposed causal beam selection\nmatches the performance of conventional methods while drastically reducing\ninput selection time by 94.4% and beam sweeping overhead by 59.4% by focusing\nonly on causally relevant features."}
{"id": "2508.16383", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.16383", "abs": "https://arxiv.org/abs/2508.16383", "authors": ["Xinyu Yang", "Chenlong Deng", "Zhicheng Dou"], "title": "GLARE: Agentic Reasoning for Legal Judgment Prediction", "comment": null, "summary": "Legal judgment prediction (LJP) has become increasingly important in the\nlegal field. In this paper, we identify that existing large language models\n(LLMs) have significant problems of insufficient reasoning due to a lack of\nlegal knowledge. Therefore, we introduce GLARE, an agentic legal reasoning\nframework that dynamically acquires key legal knowledge by invoking different\nmodules, thereby improving the breadth and depth of reasoning. Experiments\nconducted on the real-world dataset verify the effectiveness of our method.\nFurthermore, the reasoning chain generated during the analysis process can\nincrease interpretability and provide the possibility for practical\napplications."}
{"id": "2508.16463", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.16463", "abs": "https://arxiv.org/abs/2508.16463", "authors": ["Aniello Panariello", "Emanuele Frascaroli", "Pietro Buzzega", "Lorenzo Bonicelli", "Angelo Porrello", "Simone Calderara"], "title": "Modular Embedding Recomposition for Incremental Learning", "comment": "Accepted to the 36th British Machine Vision Conference (BMVC 2025),\n  Sheffield, UK", "summary": "The advent of pre-trained Vision-Language Models (VLMs) has significantly\ntransformed Continual Learning (CL), mainly due to their zero-shot\nclassification abilities. Such proficiency makes VLMs well-suited for\nreal-world applications, enabling robust performance on novel unseen classes\nwithout requiring adaptation. However, fine-tuning remains essential when\ndownstream tasks deviate significantly from the pre-training domain. Prior CL\napproaches primarily focus on preserving the zero-shot capabilities of VLMs\nduring incremental fine-tuning on a downstream task. We take a step further by\ndevising an approach that transforms preservation into enhancement of the\nzero-shot capabilities of VLMs. Our approach, named MoDular Embedding\nRecomposition (MoDER), introduces a modular framework that trains multiple\ntextual experts, each specialized in a single seen class, and stores them in a\nfoundational hub. At inference time, for each unseen class, we query the hub\nand compose the retrieved experts to synthesize a refined prototype that\nimproves classification. We show the effectiveness of our method across two\npopular zero-shot incremental protocols, Class-IL and MTIL, comprising a total\nof 14 datasets. The codebase is available at\nhttps://github.com/aimagelab/mammoth."}
{"id": "2508.16524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16524", "abs": "https://arxiv.org/abs/2508.16524", "authors": ["Xuan Zhang", "Zhijian Zhou", "Weidi Xu", "Yanting Miao", "Chao Qu", "Yuan Qi"], "title": "Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning", "comment": null, "summary": "Enabling neural networks to learn complex logical constraints and fulfill\nsymbolic reasoning is a critical challenge. Bridging this gap often requires\nguiding the neural network's output distribution to move closer to the symbolic\nconstraints. While diffusion models have shown remarkable generative capability\nacross various domains, we employ the powerful architecture to perform\nneuro-symbolic learning and solve logical puzzles. Our diffusion-based pipeline\nadopts a two-stage training strategy: the first stage focuses on cultivating\nbasic reasoning abilities, while the second emphasizes systematic learning of\nlogical constraints. To impose hard constraints on neural outputs in the second\nstage, we formulate the diffusion reasoner as a Markov decision process and\ninnovatively fine-tune it with an improved proximal policy optimization\nalgorithm. We utilize a rule-based reward signal derived from the logical\nconsistency of neural outputs and adopt a flexible strategy to optimize the\ndiffusion reasoner's policy. We evaluate our methodology on some classical\nsymbolic reasoning benchmarks, including Sudoku, Maze, pathfinding and\npreference learning. Experimental results demonstrate that our approach\nachieves outstanding accuracy and logical consistency among neural networks."}
{"id": "2508.16571", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.16571", "abs": "https://arxiv.org/abs/2508.16571", "authors": ["Alisa Vinogradova", "Vlad Vinogradov", "Dmitrii Radkevich", "Ilya Yasny", "Dmitry Kobyzev", "Ivan Izmailov", "Katsiaryna Yanchanka", "Andrey Doronichev"], "title": "LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence", "comment": null, "summary": "In this paper, we describe and benchmark a competitor-discovery component\nused within an agentic AI system for fast drug asset due diligence. A\ncompetitor-discovery AI agent, given an indication, retrieves all drugs\ncomprising the competitive landscape of that indication and extracts canonical\nattributes for these drugs. The competitor definition is investor-specific, and\ndata is paywalled/licensed, fragmented across registries, ontology-mismatched\nby indication, alias-heavy for drug names, multimodal, and rapidly changing.\nAlthough considered the best tool for this problem, the current LLM-based AI\nsystems aren't capable of reliably retrieving all competing drug names, and\nthere is no accepted public benchmark for this task. To address the lack of\nevaluation, we use LLM-based agents to transform five years of multi-modal,\nunstructured diligence memos from a private biotech VC fund into a structured\nevaluation corpus mapping indications to competitor drugs with normalized\nattributes. We also introduce a competitor validating LLM-as-a-judge agent that\nfilters out false positives from the list of predicted competitors to maximize\nprecision and suppress hallucinations. On this benchmark, our\ncompetitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research\n(65%) and Perplexity Labs (60%). The system is deployed in production with\nenterprise users; in a case study with a biotech VC investment fund, analyst\nturnaround time dropped from 2.5 days to $\\sim$3 hours ($\\sim$20x) for the\ncompetitive analysis."}
{"id": "2508.15858", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15858", "abs": "https://arxiv.org/abs/2508.15858", "authors": ["Maarten Buyl", "Yousra Fettach", "Guillaume Bied", "Tijl De Bie"], "title": "Building and Measuring Trust between Large Language Models", "comment": null, "summary": "As large language models (LLMs) increasingly interact with each other, most\nnotably in multi-agent setups, we may expect (and hope) that `trust'\nrelationships develop between them, mirroring trust relationships between human\ncolleagues, friends, or partners. Yet, though prior work has shown LLMs to be\ncapable of identifying emotional connections and recognizing reciprocity in\ntrust games, little remains known about (i) how different strategies to build\ntrust compare, (ii) how such trust can be measured implicitly, and (iii) how\nthis relates to explicit measures of trust.\n  We study these questions by relating implicit measures of trust, i.e.\nsusceptibility to persuasion and propensity to collaborate financially, with\nexplicit measures of trust, i.e. a dyadic trust questionnaire well-established\nin psychology. We build trust in three ways: by building rapport dynamically,\nby starting from a prewritten script that evidences trust, and by adapting the\nLLMs' system prompt. Surprisingly, we find that the measures of explicit trust\nare either little or highly negatively correlated with implicit trust measures.\nThese findings suggest that measuring trust between LLMs by asking their\nopinion may be deceiving. Instead, context-specific and implicit measures may\nbe more informative in understanding how LLMs trust each other."}
