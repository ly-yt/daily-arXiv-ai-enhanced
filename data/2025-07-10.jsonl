{"id": "2507.06278", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06278", "abs": "https://arxiv.org/abs/2507.06278", "authors": ["Kemboi Cheruiyot", "Nickson Kiprotich", "Vyacheslav Kungurtsev", "Kennedy Mugo", "Vivian Mwirigi", "Marvin Ngesa"], "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes", "comment": null, "summary": "The increasing interest in research and innovation towards the development of\nautonomous agents presents a number of complex yet important scenarios of\nmultiple AI Agents interacting with each other in an environment. The\nparticular setting can be understood as exhibiting three possibly topologies of\ninteraction - centrally coordinated cooperation, ad-hoc interaction and\ncooperation, and settings with noncooperative incentive structures. This\narticle presents a comprehensive survey of all three domains, defined under the\nformalism of Federal Reinforcement Learning (RL), Decentralized RL, and\nNoncooperative RL, respectively. Highlighting the structural similarities and\ndistinctions, we review the state of the art in these subjects, primarily\nexplored and developed only recently in the literature. We include the\nformulations as well as known theoretical guarantees and highlights and\nlimitations of numerical performance."}
{"id": "2507.06499", "categories": ["cs.MA", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.06499", "abs": "https://arxiv.org/abs/2507.06499", "authors": ["Shivangi Agarwal", "Adi Asija", "Sanjit K. Kaul", "Arani Bhattacharya", "Saket Anand"], "title": "Learning To Communicate Over An Unknown Shared Network", "comment": "22 pages, 15 figures, 4 tables", "summary": "As robots (edge-devices, agents) find uses in an increasing number of\nsettings and edge-cloud resources become pervasive, wireless networks will\noften be shared by flows of data traffic that result from communication between\nagents and corresponding edge-cloud. In such settings, agent communicating with\nthe edge-cloud is unaware of state of network resource, which evolves in\nresponse to not just agent's own communication at any given time but also to\ncommunication by other agents, which stays unknown to the agent. We address\nchallenge of an agent learning a policy that allows it to decide whether or not\nto communicate with its cloud node, using limited feedback it obtains from its\nown attempts to communicate, to optimize its utility. The policy generalizes\nwell to any number of other agents sharing the network and must not be trained\nfor any particular network configuration. Our proposed policy is a DRL model\nQuery Net (QNet) that we train using a proposed simulation-to-real framework.\nOur simulation model has just one parameter and is agnostic to specific\nconfigurations of any wireless network. It allows training an agent's policy\nover a wide range of outcomes that an agent's communication with its edge-cloud\nnode may face when using a shared network, by suitably randomizing the\nsimulation parameter. We propose a learning algorithm that addresses challenges\nobserved in training QNet. We validate our simulation-to-real driven approach\nthrough experiments conducted on real wireless networks including WiFi and\ncellular. We compare QNet with other policies to demonstrate its efficacy. WiFi\nexperiments involved as few as five agents, resulting in barely any contention\nfor the network, to as many as fifty agents, resulting in severe contention.\nThe cellular experiments spanned a broad range of network conditions, with\nbaseline RTT ranging from a low of 0.07 second to a high of 0.83 second."}
{"id": "2507.06520", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06520", "abs": "https://arxiv.org/abs/2507.06520", "authors": ["Xinyuan Song", "Zeyu Wang", "Siyi Wu", "Tianyu Shi", "Lynn Ai"], "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration", "comment": null, "summary": "We present Gradientsys, a next-generation multi-agent scheduling framework\nthat coordinates diverse specialized AI agents using a typed Model-Context\nProtocol (MCP) and a ReAct-based dynamic planning loop. At its core,\nGradientsys employs an LLM-powered scheduler for intelligent one-to-many task\ndispatch, enabling parallel execution of heterogeneous agents such as PDF\nparsers, web search modules, GUI controllers, and web builders. The framework\nsupports hybrid synchronous/asynchronous execution, respects agent capacity\nconstraints, and incorporates a robust retry-and-replan mechanism to handle\nfailures gracefully. To promote transparency and trust, Gradientsys includes an\nobservability layer streaming real-time agent activity and intermediate\nreasoning via Server-Sent Events (SSE). We offer an architectural overview and\nevaluate Gradientsys against existing frameworks in terms of extensibility,\nscheduling topology, tool reusability, parallelism, and observability.\nExperiments on the GAIA general-assistant benchmark show that Gradientsys\nachieves higher task success rates with reduced latency and lower API costs\ncompared to a MinionS-style baseline, demonstrating the strength of its\nLLM-driven multi-agent orchestration."}
{"id": "2507.07074", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07074", "abs": "https://arxiv.org/abs/2507.07074", "authors": ["Farhaan Ebadulla", "Dharini Hindlatti", "Srinivaasan NS", "Apoorva VH", "Ayman Aftab"], "title": "Graph-Based Complexity Metrics for Multi-Agent Curriculum Learning: A Validated Approach to Task Ordering in Cooperative Coordination Environments", "comment": "6 Pages, 3 Figures", "summary": "Multi-agent reinforcement learning (MARL) faces significant challenges in\ntask sequencing and curriculum design, particularly for cooperative\ncoordination scenarios. While curriculum learning has demonstrated success in\nsingle-agent domains, principled approaches for multi-agent coordination remain\nlimited due to the absence of validated task complexity metrics. This approach\npresents a graph-based coordination complexity metric that integrates agent\ndependency entropy, spatial interference patterns, and goal overlap analysis to\npredict task difficulty in multi-agent environments. The complexity metric\nachieves strong empirical validation with rho = 0.952 correlation (p < 0.001)\nbetween predicted complexity and empirical difficulty determined by random\nagent performance evaluation. This approach evaluates the curriculum learning\nframework using MADDPG across two distinct coordination environments: achieving\n56x performance improvement in tight coordination tasks (MultiWalker) and\ndemonstrating systematic task progression in cooperative navigation (Simple\nSpread). Through systematic analysis, coordination tightness emerges as a\npredictor of curriculum learning effectiveness, where environments requiring\nstrict agent interdependence benefit substantially from structured progression.\nThis approach provides a validated complexity metric for multi-agent curriculum\ndesign and establishes empirical guidelines for multi-robot coordination\napplications."}
{"id": "2507.06373", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.06373", "abs": "https://arxiv.org/abs/2507.06373", "authors": ["Jeremy Fischer", "Ram Krishnamoorthy", "Vishal Kumar", "Mahdi Al-Husseini"], "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making", "comment": null, "summary": "Medical evacuation is one of the United States Army's most storied and\ncritical mission sets, responsible for efficiently and expediently evacuating\nthe battlefield ill and injured. Medical evacuation planning involves designing\na robust network of medical platforms and facilities capable of moving and\ntreating large numbers of casualties. Until now, there has not been a medium to\nsimulate these networks in a classroom setting and evaluate both offline\nplanning and online decision-making performance. This work describes the\nMedical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer\nsimulation developed in Unity that replicates battlefield constraints and\nuncertainties. MEWI accurately models patient interactions at casualty\ncollection points, ambulance exchange points, medical treatment facilities, and\nevacuation platforms. Two operational scenarios are introduced: an amphibious\nisland assault in the Pacific and a Eurasian conflict across a sprawling road\nand river network. These scenarios pit students against the clock to save as\nmany casualties as possible while adhering to doctrinal lessons learned during\ndidactic training. We visualize performance data collected from two iterations\nof the MEWI Pacific scenario executed in the United States Army's Medical\nEvacuation Doctrine Course. We consider post-wargame Likert survey data from\nstudent participants and external observer notes to identify key planning\ndecision points, document medical evacuation lessons learned, and quantify\ngeneral utility. Results indicate that MEWI participation substantially\nimproves uptake of medical evacuation lessons learned and co-operative\ndecision-making. MEWI is a substantial step forward in the field of\nhigh-fidelity training tools for medical education, and our study findings\noffer critical insights into improving medical evacuation education and\noperations across the joint force."}
{"id": "2507.06396", "categories": ["cs.AI", "cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06396", "abs": "https://arxiv.org/abs/2507.06396", "authors": ["Mandana Vaziri", "Louis Mandel", "Yuji Watanabe", "Hirokuni Kitahara", "Martin Hirzel", "Anca Sailer"], "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study", "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "summary": "Prompt engineering for LLMs remains complex, with existing frameworks either\nhiding complexity behind restrictive APIs or providing inflexible canned\npatterns that resist customization -- making sophisticated agentic programming\nchallenging. We present the Prompt Declaration Language (PDL), a novel approach\nto prompt representation that tackles this fundamental complexity by bringing\nprompts to the forefront, enabling manual and automatic prompt tuning while\ncapturing the composition of LLM calls together with rule-based code and\nexternal tools. By abstracting away the plumbing for such compositions, PDL\naims at improving programmer productivity while providing a declarative\nrepresentation that is amenable to optimization. This paper demonstrates PDL's\nutility through a real-world case study of a compliance agent. Tuning the\nprompting pattern of this agent yielded up to 4x performance improvement\ncompared to using a canned agent and prompt pattern."}
{"id": "2507.06398", "categories": ["cs.AI", "cs.CY", "68T01, 91B26, 93C15"], "pdf": "https://arxiv.org/pdf/2507.06398", "abs": "https://arxiv.org/abs/2507.06398", "authors": ["David Orban"], "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI", "comment": "13 pages, 2 figures. Revised following peer review", "summary": "This paper investigates the Jolting Technologies Hypothesis, which posits\nsuperexponential growth (increasing acceleration, or a positive third\nderivative) in the development of AI capabilities. We develop a theoretical\nframework and validate detection methodologies through Monte Carlo simulations,\nwhile acknowledging that empirical validation awaits suitable longitudinal\ndata. Our analysis focuses on creating robust tools for future empirical\nstudies and exploring the potential implications should the hypothesis prove\nvalid. The study examines how factors such as shrinking idea-to-action\nintervals and compounding iterative AI improvements drive this jolting pattern.\nBy formalizing jolt dynamics and validating detection methods through\nsimulation, this work provides the mathematical foundation necessary for\nunderstanding potential AI trajectories and their consequences for AGI\nemergence, offering insights for research and policy."}
{"id": "2507.06798", "categories": ["cs.AI", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.06798", "abs": "https://arxiv.org/abs/2507.06798", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)", "comment": "25 pages, accepted at JELIA 2025", "summary": "Dialectical systems are a mathematical formalism for modeling an agent\nupdating a knowledge base seeking consistency. Introduced in the 1970s by\nRoberto Magari, they were originally conceived to capture how a working\nmathematician or a research community refines beliefs in the pursuit of truth.\nDialectical systems also serve as natural models for the belief change of an\nautomated agent, offering a unifying, computable framework for dynamic belief\nmanagement.\n  The literature distinguishes three main models of dialectical systems:\n(d-)dialectical systems based on revising beliefs when they are seen to be\ninconsistent, p-dialectical systems based on revising beliefs based on finding\na counterexample, and q-dialectical systems which can do both. We answer an\nopen problem in the literature by proving that q-dialectical systems are\nstrictly more powerful than p-dialectical systems, which are themselves known\nto be strictly stronger than (d-)dialectical systems. This result highlights\nthe complementary roles of counterexample and contradiction in automated belief\nrevision, and thus also in the reasoning processes of mathematicians and\nresearch communities."}
{"id": "2507.06852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06852", "abs": "https://arxiv.org/abs/2507.06852", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "SCC-recursiveness in infinite argumentation (extended version)", "comment": "26 pages, accepted at JELIA 2025", "summary": "Argumentation frameworks (AFs) are a foundational tool in artificial\nintelligence for modeling structured reasoning and conflict. SCC-recursiveness\nis a well-known design principle in which the evaluation of arguments is\ndecomposed according to the strongly connected components (SCCs) of the attack\ngraph, proceeding recursively from \"higher\" to \"lower\" components. While\nSCC-recursive semantics such as \\cft and \\stgt have proven effective for finite\nAFs, Baumann and Spanring showed the failure of SCC-recursive semantics to\ngeneralize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite\nsetting. We systematically evaluate these semantics using Baroni and Giacomin's\nestablished criteria, showing in particular that directionality fails in\ngeneral. We then examine these semantics' behavior in finitary frameworks,\nwhere we find some of our semantics satisfy directionality. These results\nadvance the theory of infinite argumentation and lay the groundwork for\nreasoning systems capable of handling unbounded or evolving domains."}
{"id": "2507.06968", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06968", "abs": "https://arxiv.org/abs/2507.06968", "authors": ["Li Du", "Hanyu Zhao", "Yiming Ju", "Tengfei Pan"], "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report", "comment": null, "summary": "Instruction tuning has become a foundation for unlocking the capabilities of\nlarge-scale pretrained models and improving their performance on complex tasks.\nThus, the construction of high-quality instruction datasets is crucial for\nenhancing model performance and generalizability. Although current instruction\ndatasets have reached tens of millions of samples, models finetuned on them may\nstill struggle with complex instruction following and tasks in rare domains.\nThis is primarily due to limited expansion in both ``coverage'' (coverage of\ntask types and knowledge areas) and ``depth'' (instruction complexity) of the\ninstruction set. To address this issue, we propose a systematic instruction\ndata construction framework, which integrates a hierarchical labeling system,\nan informative seed selection algorithm, an evolutionary data synthesis\nprocess, and a model deficiency diagnosis with targeted data generation. These\ncomponents form an iterative closed-loop to continuously enhance the coverage\nand depth of instruction data. Based on this framework, we construct\nInfinityInstruct-Subject, a high-quality dataset containing ~1.5 million\ninstructions. Experiments on multiple foundation models and benchmark tasks\ndemonstrate its effectiveness in improving instruction-following capabilities.\nFurther analyses suggest that InfinityInstruct-Subject shows enlarged coverage\nand depth compared to comparable synthesized instruction datasets. Our work\nlays a theoretical and practical foundation for the efficient, continuous\nevolution of instruction datasets, moving from data quantity expansion to\nqualitative improvement."}
{"id": "2507.06993", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.06993", "abs": "https://arxiv.org/abs/2507.06993", "authors": ["Jieren Deng", "Aleksandar Cvetkovic", "Pak Kiu Chung", "Dragomir Yankov", "Chiqun Zhang"], "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation", "comment": null, "summary": "Traditional travel-planning systems are often static and fragmented, leaving\nthem ill-equipped to handle real-world complexities such as evolving\nenvironmental conditions and unexpected itinerary disruptions. In this paper,\nwe identify three gaps between existing service providers causing frustrating\nuser experience: intelligent trip planning, precision \"last-100-meter\"\nnavigation, and dynamic itinerary adaptation. We propose three cooperative\nagents: a Travel Planning Agent that employs grid-based spatial grounding and\nmap analysis to help resolve complex multi-modal user queries; a Destination\nAssistant Agent that provides fine-grained guidance for the final navigation\nleg of each journey; and a Local Discovery Agent that leverages image\nembeddings and Retrieval-Augmented Generation (RAG) to detect and respond to\ntrip plan disruptions. With evaluations and experiments, our system\ndemonstrates substantial improvements in query interpretation, navigation\naccuracy, and disruption resilience, underscoring its promise for applications\nfrom urban exploration to emergency response."}
{"id": "2507.07017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07017", "abs": "https://arxiv.org/abs/2507.07017", "authors": ["Tianyu Zheng", "Tianshun Xing", "Qingshui Gu", "Taoran Liang", "Xingwei Qu", "Xin Zhou", "Yizhi Li", "Zhoufutu Wen", "Chenghua Lin", "Wenhao Huang", "Qian Liu", "Ge Zhang", "Zejun Ma"], "title": "First Return, Entropy-Eliciting Explore", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning\nabilities of Large Language Models (LLMs) but it struggles with unstable\nexploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a\nstructured exploration framework that identifies high-uncertainty decision\npoints in reasoning trajectories and performs targeted rollouts to construct\nsemantically grounded intermediate feedback. Our method provides targeted\nguidance without relying on dense supervision. Empirical results on\nmathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable\ntraining, produces longer and more coherent responses, and increases the\nproportion of fully correct trajectories. These results highlight the\nframework's effectiveness in improving LLM reasoning through more robust and\nstructured exploration."}
{"id": "2507.06278", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06278", "abs": "https://arxiv.org/abs/2507.06278", "authors": ["Kemboi Cheruiyot", "Nickson Kiprotich", "Vyacheslav Kungurtsev", "Kennedy Mugo", "Vivian Mwirigi", "Marvin Ngesa"], "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes", "comment": null, "summary": "The increasing interest in research and innovation towards the development of\nautonomous agents presents a number of complex yet important scenarios of\nmultiple AI Agents interacting with each other in an environment. The\nparticular setting can be understood as exhibiting three possibly topologies of\ninteraction - centrally coordinated cooperation, ad-hoc interaction and\ncooperation, and settings with noncooperative incentive structures. This\narticle presents a comprehensive survey of all three domains, defined under the\nformalism of Federal Reinforcement Learning (RL), Decentralized RL, and\nNoncooperative RL, respectively. Highlighting the structural similarities and\ndistinctions, we review the state of the art in these subjects, primarily\nexplored and developed only recently in the literature. We include the\nformulations as well as known theoretical guarantees and highlights and\nlimitations of numerical performance."}
{"id": "2507.06520", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06520", "abs": "https://arxiv.org/abs/2507.06520", "authors": ["Xinyuan Song", "Zeyu Wang", "Siyi Wu", "Tianyu Shi", "Lynn Ai"], "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration", "comment": null, "summary": "We present Gradientsys, a next-generation multi-agent scheduling framework\nthat coordinates diverse specialized AI agents using a typed Model-Context\nProtocol (MCP) and a ReAct-based dynamic planning loop. At its core,\nGradientsys employs an LLM-powered scheduler for intelligent one-to-many task\ndispatch, enabling parallel execution of heterogeneous agents such as PDF\nparsers, web search modules, GUI controllers, and web builders. The framework\nsupports hybrid synchronous/asynchronous execution, respects agent capacity\nconstraints, and incorporates a robust retry-and-replan mechanism to handle\nfailures gracefully. To promote transparency and trust, Gradientsys includes an\nobservability layer streaming real-time agent activity and intermediate\nreasoning via Server-Sent Events (SSE). We offer an architectural overview and\nevaluate Gradientsys against existing frameworks in terms of extensibility,\nscheduling topology, tool reusability, parallelism, and observability.\nExperiments on the GAIA general-assistant benchmark show that Gradientsys\nachieves higher task success rates with reduced latency and lower API costs\ncompared to a MinionS-style baseline, demonstrating the strength of its\nLLM-driven multi-agent orchestration."}
